import json
import os
import pandas as pd
!pip install transformers[torch]

from transformers import AutoModelForSeq2SeqLM, AutoTokenizer, TrainingArguments, Trainer
from datasets import Dataset

# Load example questions and answers
qa_pairs = [
    {
        "question": "Give me the top 5 customers with the most number of orders.",
        "answer": {
            "table_information": [
                {
                    "table_name": "customer_0",
                    "table_description": "Stores detailed customer information and behavior",
                    "primary_key_column": ["customer_id"],
                    "columns": [
                        {"name": "customer_id", "description": "Unique identifier for the customer", "data_type": "STRING", "format": "", "is_pii_column": "Y", "is_nullable": "N"},
                        {"name": "first_name", "description": "Customer's first name", "data_type": "STRING", "format": "CamelCase", "is_pii_column": "Y", "is_nullable": "N"},
                        {"name": "last_name", "description": "Customer's last name", "data_type": "STRING", "format": "CamelCase", "is_pii_column": "Y", "is_nullable": "N"}
                    ]
                },
                {
                    "table_name": "order",
                    "table_description": "Stores detailed records of customer orders",
                    "primary_key_column": ["order_id", "order_item_id"],
                    "columns": [
                        {"name": "order_id", "description": "Unique identifier for the order", "data_type": "STRING", "format": "", "is_pii_column": "N", "is_nullable": "N"},
                        {"name": "customer_id", "description": "Unique identifier for the customer", "data_type": "STRING", "format": "", "is_pii_column": "Y", "is_nullable": "N"}
                    ]
                }
            ],
            "relationships": [
                {"FromTable": "customer_0", "FromColumn": ["customer_id"], "ToTable": "order", "ToColumn": ["customer_id"]}
            ]
        }
    }
]

# Create dataset
dataset = Dataset.from_pandas(pd.DataFrame(qa_pairs))

# Tokenizer and model
tokenizer = AutoTokenizer.from_pretrained("facebook/bart-large")
model = AutoModelForSeq2SeqLM.from_pretrained("facebook/bart-large")

def preprocess_function(examples):
    inputs = examples['question']
    targets = [json.dumps(ans) for ans in examples['answer']]
    model_inputs = tokenizer(inputs, max_length=512, truncation=True)
    with tokenizer.as_target_tokenizer():
        labels = tokenizer(targets, max_length=512, truncation=True)
    model_inputs["labels"] = labels["input_ids"]
    return model_inputs

tokenized_datasets = dataset.map(preprocess_function, batched=True)

# Training arguments
training_args = TrainingArguments(
    output_dir="./results",
    evaluation_strategy="epoch",
    learning_rate=2e-5,
    per_device_train_batch_size=4,
    per_device_eval_batch_size=4,
    num_train_epochs=3,
    weight_decay=0.01,
)

# Trainer
trainer = Trainer(
    model=model,
    args=training_args,
    train_dataset=tokenized_datasets,
    eval_dataset=tokenized_datasets
)

# Train the model
trainer.train()
